{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Tools and Ecosystem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Data science is an interdisciplinary field that focuses on extracting insights and knowledge from data using a combination of statistics, computer science, and domain expertise. It involves the collection, cleaning, analysis, and interpretation of vast amounts of structured and unstructured data to help organizations make informed decisions. Leveraging tools like machine learning, data visualization, and predictive analytics, data science plays a crucial role in various industries, enabling advancements in areas such as healthcare, finance, marketing, and more, by transforming raw data into actionable insights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Science Languages\n",
    "- Python – Popular for its simplicity and vast libraries like NumPy, pandas, scikit-learn, and TensorFlow.\n",
    "- R – Known for statistical analysis and data visualization with packages like ggplot2 and dplyr.\n",
    "- SQL – Essential for managing and querying relational databases.\n",
    "- Java – Used for building large-scale machine learning applications.\n",
    "- Julia – Designed for high-performance numerical and scientific computing.\n",
    "- Scala – Used in big data tools like Apache Spark.\n",
    "- MATLAB – Used for mathematical modeling and simulation.\n",
    "- SAS – A specialized language for advanced analytics and statistical modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Science Libraries\n",
    "- NumPy – For numerical computing and array manipulation.\n",
    "- pandas – For data manipulation and analysis, especially with tabular data.\n",
    "- Matplotlib – For creating static, animated, and interactive visualizations.\n",
    "- Seaborn – For statistical data visualization built on top of Matplotlib.\n",
    "- SciPy – For scientific computing and technical computing.\n",
    "- scikit-learn – For machine learning algorithms and tools.\n",
    "- TensorFlow – For deep learning and machine learning applications.\n",
    "- Keras – A high-level neural networks API running on top of TensorFlow.\n",
    "- PyTorch – Another popular deep learning library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Data Science tools\n",
    "| Category                 | Tool                    | Description                                                                                     |\n",
    "|--------------------------|-------------------------|-------------------------------------------------------------------------------------------------|\n",
    "| Programming Languages     | Python                  | Widely used for data manipulation, analysis, and machine learning.                              |\n",
    "|                          | R                       | Statistical programming language primarily for data analysis and visualization.                 |\n",
    "|                          | SQL                     | Used for querying and managing data in relational databases.                                    |\n",
    "|                          | Julia                   | High-performance programming language, suitable for numerical and scientific computing.         |\n",
    "|                          | Scala                   | Often used with Apache Spark for big data processing.                                           |\n",
    "| Data Manipulation         | pandas (Python)         | Library for handling and analyzing structured data in Python.                                   |\n",
    "|                          | dplyr (R)               | Provides a grammar for data manipulation in R.                                                  |\n",
    "| Data Visualization        | Matplotlib (Python)     | Basic plotting library in Python for 2D visualizations.                                         |\n",
    "|                          | Seaborn (Python)        | Built on Matplotlib for statistical data visualization.                                         |\n",
    "|                          | ggplot2 (R)             | Advanced data visualization library in R.                                                       |\n",
    "|                          | Tableau                 | Business intelligence tool for data visualization and dashboard creation.                       |\n",
    "|                          | Power BI                | Microsoft’s data visualization and business analytics tool.                                     |\n",
    "| Machine Learning          | scikit-learn (Python)   | Python library with a wide range of machine learning algorithms.                                |\n",
    "|                          | TensorFlow (Python)     | Google’s library for deep learning and machine learning.                                        |\n",
    "|                          | PyTorch (Python)        | Deep learning framework developed by Facebook.                                                  |\n",
    "|                          | caret (R)               | Simplifies the training and tuning of machine learning models in R.                             |\n",
    "|                          | H2O.ai                  | Open-source machine learning platform for building predictive models.                           |\n",
    "| Big Data Tools            | Apache Hadoop           | Open-source framework for distributed storage and processing of large datasets.                 |\n",
    "|                          | Apache Spark            | Fast, distributed data processing framework.                                                    |\n",
    "|                          | Dask                    | Parallel computing library in Python for big data processing.                                   |\n",
    "|                          | Hive                    | Data warehousing solution built on top of Hadoop for querying large datasets using SQL.         |\n",
    "| Data Storage              | MySQL                   | Relational database management system (RDBMS) for structured data.                              |\n",
    "|                          | MongoDB                 | NoSQL database for unstructured or semi-structured data.                                        |\n",
    "|                          | Cassandra               | Distributed NoSQL database for handling large-scale data.                                       |\n",
    "|                          | Google BigQuery         | Serverless data warehouse for querying big data.                                                |\n",
    "| Cloud Platforms           | AWS (Amazon Web Services)| Cloud platform providing a variety of data science tools, including SageMaker for machine learning.|\n",
    "|                          | Google Cloud Platform   | Cloud computing platform with tools like BigQuery and AI/ML capabilities.                       |\n",
    "|                          | Microsoft Azure         | Cloud platform offering machine learning, big data, and data storage services.                  |\n",
    "| ETL Tools                 | Apache NiFi             | Tool for automating data movement between different systems (ETL).                              |\n",
    "|                          | Talend                  | ETL and data integration platform with big data capabilities.                                   |\n",
    "| Version Control           | GitHub                  | Code hosting platform for version control and collaboration.                                    |\n",
    "|                          | GitLab                  | Git repository manager with issue tracking and CI/CD pipelines.                                 |\n",
    "| Model Deployment          | Docker                  | Platform to develop, deploy, and run applications in containers.                                |\n",
    "|                          | Kubernetes              | Open-source container orchestration platform.                                                   |\n",
    "|                          | MLflow                  | Open-source platform to manage the ML lifecycle, including experimentation, reproducibility, and deployment. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Arithmetic Expressions\n",
    "Arithmetic expressions consist of numbers, variables, and arithmetic operators like +, -, *, /, and % (modulo). They are used to perform mathematical calculations.\n",
    "Below are some common examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(3*4)+5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 minutes is equal to 2.50 hours\n"
     ]
    }
   ],
   "source": [
    "# Convert minutes to hours\n",
    "minutes = 200 \n",
    "hours = minutes / 60\n",
    "\n",
    "print(f\"{minutes} minutes is equal to {hours:.2f} hours\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "- Data Collection and Preparation: Gathering, cleaning, and preprocessing data for analysis.\n",
    "- Exploratory Data Analysis (EDA): Investigating datasets to discover patterns, trends, and insights.\n",
    "- Model Building: Developing predictive or descriptive models using machine learning or statistical methods.\n",
    "- Model Evaluation: Assessing the performance and accuracy of the models using metrics and validation techniques.\n",
    "- Data Visualization: Presenting data and insights through visual representations like charts and graphs.\n",
    "- Predictive Analytics: Using models to make future predictions based on historical data.\n",
    "- Decision Making: Supporting business decisions by providing actionable insights from data.\n",
    "- Automation: Creating automated systems for data-driven decision-making and reporting.\n",
    "- Optimization: Improving processes, strategies, or algorithms to enhance performance or efficiency.\n",
    "- Communication: Effectively communicating findings and insights to stakeholders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Author</h2>\n",
    "Rohan Jagtap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "prev_pub_hash": "9e1985db9844176462bd1d5863048c9f3d17404bbc6a648be9084b0c42b29347"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
